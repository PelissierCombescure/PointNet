{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpvL68OfBEQC"
      },
      "source": [
        "# PointNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbPm1WS7UWe6"
      },
      "source": [
        "This is an implementation of [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593) using PyTorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z7n_pw4SMWl"
      },
      "source": [
        "## Getting started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGjwJhn0VTVu"
      },
      "source": [
        "Don't forget to turn on GPU if you want to start training directly. \n",
        "\n",
        "\n",
        "**Runtime** -> **Change runtime type**-> **Hardware accelerator**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "TJ47VNF7fmTS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import scipy.spatial.distance\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "from utils import write_obj_with_colors, read_off\n",
        "from pointnet_functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zncVRbuwtV2N",
        "outputId": "06d7a9b0-7dd0-4622-efea-bcaeabf36baa"
      },
      "outputs": [],
      "source": [
        "#!pip install path.py;\n",
        "from path import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vpzTlKjmlr2q"
      },
      "outputs": [],
      "source": [
        "random.seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg6HhI7eU80o"
      },
      "source": [
        "Download the [dataset](http://3dvision.princeton.edu/projects/2014/3DShapeNets/) directly to the Google Colab Runtime. It comprises 10 categories, 3,991 models for training and 908 for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7zSMatAwXAW",
        "outputId": "10d91e22-8941-4941-8675-072be664a49d"
      },
      "outputs": [],
      "source": [
        "#!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
        "#!unzip -q ModelNet10.zip;\n",
        "path = Path(\"ModelNet10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Label des classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2i_0ECIcR1X",
        "outputId": "2c746ae0-c3cc-44cf-bc35-fabdbebf9892"
      },
      "outputs": [],
      "source": [
        "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
        "classes = {folder: i for i, folder in enumerate(folders)};\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualisation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krbtoQtTXOBa"
      },
      "source": [
        "This dataset consists ofÂ **.off** files that contain meshes represented by *vertices* and *triangular faces*. \n",
        "\n",
        "We will need a function to read this type of files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TXEzgwr_Mfc0"
      },
      "outputs": [],
      "source": [
        "# def read_off(file):\n",
        "#     if 'OFF' != file.readline().strip():\n",
        "#         raise('Not a valid OFF header')\n",
        "#     n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
        "#     verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
        "#     faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
        "#     return verts, faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Example of .off file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2XqwjkJXqLE"
      },
      "source": [
        "Don't be scared of this function. It's just to display animated rotation of meshes and point clouds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2dbIQBLykGpX"
      },
      "outputs": [],
      "source": [
        "def visualize_rotate(data):\n",
        "    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
        "    frames=[]\n",
        "\n",
        "    def rotate_z(x, y, z, theta):\n",
        "        w = x+1j*y\n",
        "        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
        "\n",
        "    for t in np.arange(0, 10.26, 0.1):\n",
        "        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
        "        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n",
        "    fig = go.Figure(data=data,\n",
        "                    layout=go.Layout(\n",
        "                        updatemenus=[dict(type='buttons',\n",
        "                                    showactive=False,\n",
        "                                    y=1,\n",
        "                                    x=0.8,\n",
        "                                    xanchor='left',\n",
        "                                    yanchor='bottom',\n",
        "                                    pad=dict(t=45, r=10),\n",
        "                                    buttons=[dict(label='Play',\n",
        "                                                    method='animate',\n",
        "                                                    args=[None, dict(frame=dict(duration=50, redraw=True),\n",
        "                                                                    transition=dict(duration=0),\n",
        "                                                                    fromcurrent=True,\n",
        "                                                                    mode='immediate'\n",
        "                                                                    )]\n",
        "                                                    )\n",
        "                                            ]\n",
        "                                    )\n",
        "                                ]\n",
        "                    ),\n",
        "                    frames=frames\n",
        "            )\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0huQ5maYxBa9",
        "outputId": "21c251bf-e9f9-4b03-aa69-5ebd3f0635c0"
      },
      "outputs": [],
      "source": [
        "def modelshow(path_to_model) :\n",
        "  with open(path_to_model, 'r') as f:\n",
        "    verts, faces = read_off(f)\n",
        "    \n",
        "  i,j,k = np.array(faces).T\n",
        "  x,y,z = np.array(verts).T\n",
        "\n",
        "  visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='lightpink', opacity=0.50, i=i,j=j,k=k)]).show()\n",
        "  \n",
        "  return x,y,z, verts, faces\n",
        "  \n",
        "x, y, z, verts, faces = modelshow(path/\"bed/train/bed_0001.off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fpGrWndRVYw"
      },
      "source": [
        "This mesh definitely looks like a bed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "y9hL_IOoMVzP",
        "outputId": "b531f238-59d2-4b18-df7b-54e60f9f7662"
      },
      "outputs": [],
      "source": [
        "visualize_rotate([go.Scatter3d(x=x, y=y, z=z,\n",
        "                                   mode='markers')]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah0LVBEBRaGS"
      },
      "source": [
        "Unfortunately, that's not the case for its vertices. It would be difficult for PointNet to classify point clouds like this one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBNJ__37RBvi"
      },
      "source": [
        "First things first, let's write a function to accurately visualize point clouds so we could see vertices better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "VovK365pQ12G"
      },
      "outputs": [],
      "source": [
        "def pcshow(xs,ys,zs):\n",
        "    data=[go.Scatter3d(x=xs, y=ys, z=zs,\n",
        "                                   mode='markers')]\n",
        "    fig = visualize_rotate(data)\n",
        "    fig.update_traces(marker=dict(size=2,\n",
        "                      line=dict(width=2,\n",
        "                      color='DarkSlateGrey')),\n",
        "                      selector=dict(mode='markers'))\n",
        "    fig.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "h6CRZdE2Qw5J",
        "outputId": "062c30c7-5bf5-4809-e372-034c92dc9e68"
      },
      "outputs": [],
      "source": [
        "pcshow(x,y,z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axdsyO0wWZEB"
      },
      "source": [
        "## Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tJZHWppZ85P"
      },
      "source": [
        "As we want it to look more like a real bed, let's write a function to sample points on the surface uniformly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pee3OqfyhSdt"
      },
      "source": [
        " ### Sample points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "zCgPQhfvh7R3"
      },
      "outputs": [],
      "source": [
        "# class PointSampler(object):\n",
        "#     def __init__(self, output_size):\n",
        "#         assert isinstance(output_size, int)\n",
        "#         self.output_size = output_size\n",
        "    \n",
        "#     def triangle_area(self, pt1, pt2, pt3):\n",
        "#         side_a = np.linalg.norm(pt1 - pt2)\n",
        "#         side_b = np.linalg.norm(pt2 - pt3)\n",
        "#         side_c = np.linalg.norm(pt3 - pt1)\n",
        "#         s = 0.5 * ( side_a + side_b + side_c)\n",
        "#         return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
        "\n",
        "#     def sample_point(self, pt1, pt2, pt3):\n",
        "#         # barycentric coordinates on a triangle\n",
        "#         # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
        "#         s, t = sorted([random.random(), random.random()])\n",
        "#         f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
        "#         return (f(0), f(1), f(2))\n",
        "        \n",
        "    \n",
        "#     def __call__(self, mesh):\n",
        "#         verts, faces = mesh\n",
        "#         verts = np.array(verts)\n",
        "#         areas = np.zeros((len(faces)))\n",
        "\n",
        "#         for i in range(len(areas)):\n",
        "#             areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
        "#                                            verts[faces[i][1]],\n",
        "#                                            verts[faces[i][2]]))\n",
        "            \n",
        "#         sampled_faces = (random.choices(faces, \n",
        "#                                       weights=areas,\n",
        "#                                       cum_weights=None,\n",
        "#                                       k=self.output_size))\n",
        "        \n",
        "#         sampled_points = np.zeros((self.output_size, 3))\n",
        "\n",
        "#         for i in range(len(sampled_faces)):\n",
        "#             sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
        "#                                                    verts[sampled_faces[i][1]],\n",
        "#                                                    verts[sampled_faces[i][2]]))\n",
        "        \n",
        "#         return sampled_points\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwg7LG6mkzgN"
      },
      "outputs": [],
      "source": [
        "pointcloud = PointSampler(3000)((verts, faces))\n",
        "pcshow(*pointcloud.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5ZsXeLOrFTT"
      },
      "source": [
        "This pointcloud looks much more like a bed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXU9PdRqbbBx"
      },
      "source": [
        "### Normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCduIRX6uiDs"
      },
      "source": [
        "Unit sphere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "UR3r0WPdWbHN"
      },
      "outputs": [],
      "source": [
        "# class Normalize(object):\n",
        "#     def __call__(self, pointcloud):\n",
        "#         assert len(pointcloud.shape)==2\n",
        "        \n",
        "#         norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
        "#         norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "#         return  norm_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfMnH_o8aIWe"
      },
      "outputs": [],
      "source": [
        "norm_pointcloud = Normalize()(pointcloud)\n",
        "pcshow(*norm_pointcloud.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTz_SFrDhezz"
      },
      "source": [
        "Notice that axis limits have changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LtFfliNuxw3"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbYrmnasZAUg"
      },
      "source": [
        "Let's add *random rotation* of the whole pointcloud and random noise to its points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "FHAvoR7wuwS6"
      },
      "outputs": [],
      "source": [
        "# class RandRotation_z(object):\n",
        "#     def __call__(self, pointcloud):\n",
        "#         assert len(pointcloud.shape)==2\n",
        "\n",
        "#         theta = random.random() * 2. * math.pi\n",
        "#         rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
        "#                                [ math.sin(theta),  math.cos(theta),    0],\n",
        "#                                [0,                             0,      1]])\n",
        "        \n",
        "#         rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
        "#         return  rot_pointcloud\n",
        "    \n",
        "# class RandomNoise(object):\n",
        "#     def __call__(self, pointcloud):\n",
        "#         assert len(pointcloud.shape)==2\n",
        "\n",
        "#         noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
        "    \n",
        "#         noisy_pointcloud = pointcloud + noise\n",
        "#         return  noisy_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aektc3DZwbc9"
      },
      "outputs": [],
      "source": [
        "rot_pointcloud = RandRotation_z()(norm_pointcloud)\n",
        "noisy_rot_pointcloud = RandomNoise()(rot_pointcloud)\n",
        "pcshow(*noisy_rot_pointcloud.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE6QmxhRbwsY"
      },
      "source": [
        "### ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ctHIvE-Kbr-m"
      },
      "outputs": [],
      "source": [
        "# class ToTensor(object):\n",
        "#     def __call__(self, pointcloud):\n",
        "#         assert len(pointcloud.shape)==2\n",
        "\n",
        "#         return torch.from_numpy(pointcloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7FK8nVrel4z",
        "outputId": "a753657a-fd03-402d-aae7-6a68f031d6ae"
      },
      "outputs": [],
      "source": [
        "ToTensor()(noisy_rot_pointcloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "IdQhWT4Q1GbF"
      },
      "outputs": [],
      "source": [
        "# def default_transforms():\n",
        "#     return transforms.Compose([\n",
        "#                                 PointSampler(1024),\n",
        "#                                 Normalize(),\n",
        "#                                 ToTensor()\n",
        "#                               ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMIT1MeNSSO8"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sl3iM3CZM5n"
      },
      "source": [
        "Now we can create a [custom PyTorch Dataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "i06OYFNR8fa_"
      },
      "outputs": [],
      "source": [
        "# class PointCloudData(Dataset):\n",
        "#     def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
        "#         self.root_dir = root_dir\n",
        "#         folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
        "#         self.classes = {folder: i for i, folder in enumerate(folders)}\n",
        "#         self.transforms = transform if not valid else default_transforms()\n",
        "#         self.valid = valid\n",
        "#         self.files = []\n",
        "#         for category in self.classes.keys():\n",
        "#             new_dir = root_dir/Path(category)/folder\n",
        "#             for file in os.listdir(new_dir):\n",
        "#                 if file.endswith('.off'):\n",
        "#                     sample = {}\n",
        "#                     sample['pcd_path'] = new_dir/file\n",
        "#                     sample['category'] = category\n",
        "#                     #sample['filename'] = file\n",
        "#                     self.files.append(sample)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.files)\n",
        "\n",
        "#     def __preproc__(self, file):\n",
        "#         verts, faces = read_off(file)\n",
        "#         if self.transforms:\n",
        "#             pointcloud = self.transforms((verts, faces))\n",
        "#         return pointcloud\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         pcd_path = self.files[idx]['pcd_path']\n",
        "#         category = self.files[idx]['category']\n",
        "#         #filename = pcd_path.name  # Get the filename\n",
        "        \n",
        "#         with open(pcd_path, 'r') as f:\n",
        "#             pointcloud = self.__preproc__(f)\n",
        "            \n",
        "#         return {'pointcloud': pointcloud, \n",
        "#                 'category': self.classes[category],\n",
        "#                 'filename': pcd_path.name  # Return the filename\n",
        "#         }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOEaUDwzZY3v"
      },
      "source": [
        "Transforms for training. 1024 points per cloud as in the paper!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "4pOl95glmphX"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                    PointSampler(1024),\n",
        "                    Normalize(),\n",
        "                    RandRotation_z(),\n",
        "                    RandomNoise(),\n",
        "                    ToTensor()\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "xpDsEx00mZrx"
      },
      "outputs": [],
      "source": [
        "train_ds = PointCloudData(path, transform=train_transforms)\n",
        "valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbIZKqkIrdQE",
        "outputId": "e9426561-c73d-4a20-d332-79249c10e6e7"
      },
      "outputs": [],
      "source": [
        "inv_classes = {i: cat for cat, i in train_ds.classes.items()};\n",
        "print(inv_classes)\n",
        "print('Train dataset size: ', len(train_ds))\n",
        "print('Valid dataset size: ', len(valid_ds))\n",
        "print('Number of classes: ', len(train_ds.classes))\n",
        "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# num = 215\n",
        "\n",
        "# # model dans un PointCloudData\n",
        "# name = valid_ds.__getitem__(num)['filename'].split('.')[0]\n",
        "# pt_cloud = valid_ds.__getitem__(num)['pointcloud'].numpy()\n",
        "# cat = valid_ds.__getitem__(num)['category']\n",
        "# pcshow(*pt_cloud.T)\n",
        "\n",
        "# # Model init \n",
        "# with open(path/inv_classes[cat]+\"/test/\"+name+\".off\", 'r') as f:\n",
        "#   verts, faces = read_off(f)\n",
        "# i,j,k = np.array(faces).T\n",
        "# x,y,z = np.array(verts).T\n",
        "# visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='lightpink', opacity=0.50, i=i,j=j,k=k)]).show()\n",
        "\n",
        "\n",
        "# print('Category: ', inv_classes[cat], name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "cVGtKLa4PthS"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# d = valid_loader.dataset\n",
        "\n",
        "# num2 = num\n",
        "# # model dans un PointCloudData\n",
        "# name = d.__getitem__(num2)['filename'].split('.')[0]\n",
        "# pt_cloud = d.__getitem__(num2)['pointcloud'].numpy()\n",
        "# cat = d.__getitem__(num2)['category']\n",
        "# pcshow(*pt_cloud.T)\n",
        "\n",
        "# # Model init \n",
        "# with open(path/inv_classes[cat]+\"/test/\"+name+\".off\", 'r') as f:\n",
        "#   verts, faces = read_off(f)\n",
        "# i,j,k = np.array(faces).T\n",
        "# x,y,z = np.array(verts).T\n",
        "# visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='lightpink', opacity=0.50, i=i,j=j,k=k)]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isb_97zOA8Tl"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ZV20opgrv23I"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import numpy as np\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class Tnet(nn.Module):\n",
        "#    def __init__(self, k=3):\n",
        "#       super().__init__()\n",
        "#       self.k=k\n",
        "#       self.conv1 = nn.Conv1d(k,64,1)\n",
        "#       self.conv2 = nn.Conv1d(64,128,1)\n",
        "#       self.conv3 = nn.Conv1d(128,1024,1)\n",
        "#       self.fc1 = nn.Linear(1024,512)\n",
        "#       self.fc2 = nn.Linear(512,256)\n",
        "#       self.fc3 = nn.Linear(256,k*k)\n",
        "\n",
        "#       self.bn1 = nn.BatchNorm1d(64)\n",
        "#       self.bn2 = nn.BatchNorm1d(128)\n",
        "#       self.bn3 = nn.BatchNorm1d(1024)\n",
        "#       self.bn4 = nn.BatchNorm1d(512)\n",
        "#       self.bn5 = nn.BatchNorm1d(256)\n",
        "       \n",
        "\n",
        "#    def forward(self, input):\n",
        "#       # input.shape == (bs,n,3)\n",
        "#       bs = input.size(0)\n",
        "#       xb = F.relu(self.bn1(self.conv1(input)))\n",
        "#       xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "#       xb = F.relu(self.bn3(self.conv3(xb)))\n",
        "#       pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "#       flat = nn.Flatten(1)(pool)\n",
        "#       xb = F.relu(self.bn4(self.fc1(flat)))\n",
        "#       xb = F.relu(self.bn5(self.fc2(xb)))\n",
        "      \n",
        "#       #initialize as identity\n",
        "#       init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "#       if xb.is_cuda:\n",
        "#         init=init.cuda()\n",
        "#       matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
        "#       return matrix\n",
        "\n",
        "\n",
        "# class Transform(nn.Module):\n",
        "#    def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.input_transform = Tnet(k=3)\n",
        "#         self.feature_transform = Tnet(k=64)\n",
        "#         self.conv1 = nn.Conv1d(3,64,1)\n",
        "\n",
        "#         self.conv2 = nn.Conv1d(64,128,1)\n",
        "#         self.conv3 = nn.Conv1d(128,1024,1)\n",
        "       \n",
        "\n",
        "#         self.bn1 = nn.BatchNorm1d(64)\n",
        "#         self.bn2 = nn.BatchNorm1d(128)\n",
        "#         self.bn3 = nn.BatchNorm1d(1024)\n",
        "       \n",
        "#    def forward(self, input):\n",
        "#         matrix3x3 = self.input_transform(input)\n",
        "#         # batch matrix multiplication\n",
        "#         xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
        "\n",
        "#         xb = F.relu(self.bn1(self.conv1(xb)))\n",
        "\n",
        "#         matrix64x64 = self.feature_transform(xb)\n",
        "#         xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
        "\n",
        "#         xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "#         per_point_features = self.bn3(self.conv3(xb))  # Extract per-point features before pooling\n",
        "#         xb = nn.MaxPool1d(per_point_features.size(-1))(per_point_features)\n",
        "#         output = nn.Flatten(1)(xb)\n",
        "#         return output, per_point_features, matrix3x3, matrix64x64\n",
        "\n",
        "# class PointNet(nn.Module):\n",
        "#     def __init__(self, classes = 10):\n",
        "#         super().__init__()\n",
        "#         self.transform = Transform()\n",
        "#         self.fc1 = nn.Linear(1024, 512)\n",
        "#         self.fc2 = nn.Linear(512, 256)\n",
        "#         self.fc3 = nn.Linear(256, classes)\n",
        "        \n",
        "\n",
        "#         self.bn1 = nn.BatchNorm1d(512)\n",
        "#         self.bn2 = nn.BatchNorm1d(256)\n",
        "#         self.dropout = nn.Dropout(p=0.3)\n",
        "#         self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         xb, per_point_features, matrix3x3, matrix64x64 = self.transform(input)\n",
        "#         xb = F.relu(self.bn1(self.fc1(xb)))\n",
        "#         xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
        "#         output = self.fc3(xb)\n",
        "#         return self.logsoftmax(output), per_point_features, matrix3x3, matrix64x64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "580NErhyP1zD"
      },
      "outputs": [],
      "source": [
        "# def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
        "#     criterion = torch.nn.NLLLoss()\n",
        "#     bs=outputs.size(0)\n",
        "#     id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
        "#     id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
        "#     if outputs.is_cuda:\n",
        "#         id3x3=id3x3.cuda()\n",
        "#         id64x64=id64x64.cuda()\n",
        "#     diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
        "#     diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
        "#     return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mLBRcfwP2Sq"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUJOEaWdmsRD"
      },
      "source": [
        "You can find a pretrained model [here](https://drive.google.com/open?id=1nDG0maaqoTkRkVsOLtUAR9X3kn__LMSL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvmmwhcePvt2",
        "outputId": "ab33da86-11c1-4391-e520-186003d153bc"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "l_DXKkfMPxP0"
      },
      "outputs": [],
      "source": [
        "pointnet = PointNet()\n",
        "pointnet.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "4ST7F9E5P0BI"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Rg8obt6FP6Ff"
      },
      "outputs": [],
      "source": [
        "# def train(model, train_loader, opti = optimizer, device = device, val_loader=None,  epochs=15, save=True):\n",
        "#     for epoch in range(epochs): \n",
        "#         model.train()\n",
        "#         running_loss = 0.0\n",
        "#         for i, data in enumerate(train_loader, 0):\n",
        "#             inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
        "#             opti.zero_grad()\n",
        "#             outputs, m3x3, m64x64 = model(inputs.transpose(1,2))\n",
        "\n",
        "#             loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
        "#             loss.backward()\n",
        "#             opti.step()\n",
        "\n",
        "#             # print statistics\n",
        "#             running_loss += loss.item()\n",
        "#             if i % 10 == 9:    # print every 10 mini-batches\n",
        "#                     print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
        "#                         (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
        "#                     running_loss = 0.0\n",
        "\n",
        "#         model.eval()\n",
        "#         correct = total = 0\n",
        "\n",
        "#         # validation\n",
        "#         if val_loader:\n",
        "#             with torch.no_grad():\n",
        "#                 for data in val_loader:\n",
        "#                     inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
        "#                     outputs, __, __ = model(inputs.transpose(1,2))\n",
        "#                     _, predicted = torch.max(outputs.data, 1)\n",
        "#                     total += labels.size(0)\n",
        "#                     correct += (predicted == labels).sum().item()\n",
        "#             val_acc = 100. * correct / total\n",
        "#             print('Valid accuracy: %d %%' % val_acc)\n",
        "\n",
        "#         # save the model\n",
        "#         if save:\n",
        "#             torch.save(model.state_dict(), \"save_\"+str(epoch)+\".pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "Lp3uFKomP8AU",
        "outputId": "31540a39-cfcd-48b1-bfd1-94c2e3a9a353"
      },
      "outputs": [],
      "source": [
        "#train(pointnet, train_loader, valid_loader,  save=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8W4gOI_P9a9"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "_iDtAJoYH4hE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "pU70YWA7P-I_"
      },
      "outputs": [],
      "source": [
        "pointnet = PointNet()\n",
        "#pointnet.load_state_dict(torch.load('save.pth'))\n",
        "pointnet.load_state_dict(torch.load('save.pth', map_location=torch.device('cpu')))  # or use 'cuda' if using GPU\n",
        "pointnet.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54EP7PAyC2iQ",
        "outputId": "a9469e95-2943-40f8-c699-b4031b6f9811"
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(valid_loader):\n",
        "        print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n",
        "                \n",
        "        inputs, labels, filenames = data['pointcloud'].float(), data['category'], data['filename']\n",
        "        print(inputs.shape)\n",
        "        outputs, per_point_features, __, __ = pointnet(inputs.transpose(1,2))\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        all_preds += list(preds.numpy())\n",
        "        all_labels += list(labels.numpy())    \n",
        "        \n",
        "        break    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Critical points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_dataset = valid_loader.dataset\n",
        "\n",
        "num2 = 222"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "name = valid_dataset.__getitem__(num2)['filename'].split('.')[0]\n",
        "cat = valid_dataset.__getitem__(num2)['category']; print(name, inv_classes[cat])\n",
        "pt_cloud_init = valid_dataset.__getitem__(num2)['pointcloud'].float();  #print(pt_cloud_init.shape, pt_cloud_init.dtype)\n",
        "pt_cloud_reshape = pt_cloud_init.unsqueeze(0).float(); print(pt_cloud_reshape.shape, pt_cloud_reshape.dtype)\n",
        "\n",
        "# Assuming 'point_cloud' has shape [B, 3, N], where B is batch size, 3 are coordinates, N is number of points\n",
        "outputs, per_point_features, _, _ = pointnet(pt_cloud_reshape.transpose(1,2))\n",
        "\n",
        "# Apply max pooling to get the global feature and indices of critical points\n",
        "global_feature, indices = torch.max(per_point_features, dim=2)\n",
        "\n",
        "# Extract critical points from the original point cloud\n",
        "idx_critical_points = set([item for sublist in indices.tolist() for item in sublist]); len(idx_critical_points)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pcshow(*pt_cloud_init.T)\n",
        "_, _, _, _, _ = modelshow(path/inv_classes[cat]+\"/test/\"+name+\".off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def write_obj_with_colors(pt_cloud, idx_critical_pts, file_name, path_outputs_folder = \"\", kind_of_outputs = {'critical and non-critical points' : True, 'only critical points' : True, 'objet' : True}):\n",
        "#     \"\"\"\n",
        "#     Writes a point cloud to an .obj file with specific points colored in red.\n",
        "#     Other points are colored in black.\n",
        "    \n",
        "#     Args:\n",
        "#         pt_cloud (torch.Tensor): Tensor of shape (1, 1024, 3) containing the point cloud.\n",
        "#         idx_critical_pts (set): Indices of points to color red.\n",
        "#         output_file (str): Path of the output .obj file.\n",
        "#     \"\"\"\n",
        "#     pt_cloud = pt_cloud.squeeze(0)  # Remove the first dimension to get shape (1024, 3)\n",
        "\n",
        "#     # Critical points ET les autres : 1024 pts\n",
        "#     if kind_of_outputs['critical and non-critical points']:\n",
        "#         with open(path_outputs_folder+'critical_pts_AND_'+file_name+'.obj', 'w') as f:\n",
        "#             for idx, (x, y, z) in enumerate(pt_cloud):\n",
        "#                 if idx in idx_critical_pts:\n",
        "#                     # Red color for critical points (1.0 0.0 0.0)\n",
        "#                     f.write(f\"v {x.item()} {y.item()} {z.item()} 1.0 0.0 0.0\\n\")\n",
        "#                 else:\n",
        "#                     # Black color for non-critical points (0.0 0.0 0.0)\n",
        "#                     f.write(f\"v {x.item()} {y.item()} {z.item()} 0.0 0.0 0.0\\n\")\n",
        "#         print(f\"OBJ file saved to {path_outputs_folder+'critical_pts_and_'+file_name+'.obj'}\")\n",
        "        \n",
        "#     # QUE les Critical points : len(idx_critical_pts) pts\n",
        "#     if kind_of_outputs['only critical points']:\n",
        "#         with open(path_outputs_folder+'critical_pts_OF_'+file_name+'.obj', 'w') as f:\n",
        "#             for idx, (x, y, z) in enumerate(pt_cloud):\n",
        "#                 if idx in idx_critical_pts:\n",
        "#                     # Red color for critical points (1.0 0.0 0.0)\n",
        "#                     f.write(f\"v {x.item()} {y.item()} {z.item()} 1.0 0.0 0.0\\n\")\n",
        "#         print(f\"OBJ file saved to {path_outputs_folder+'critical_pts_of_'+file_name+'.obj'}\")\n",
        "        \n",
        "#     # TOUT les pts SANS DISTINCTION : 1024 pts\n",
        "#     if kind_of_outputs['only critical points']:\n",
        "#         with open(path_outputs_folder+'all_pts_OF_'+file_name+'.obj', 'w') as f:\n",
        "#             for idx, (x, y, z) in enumerate(pt_cloud):\n",
        "#                 f.write(f\"v {x.item()} {y.item()} {z.item()}\\n\")\n",
        "#         print(f\"OBJ file saved to {path_outputs_folder+'all_pts_OF_'+file_name+'.obj'}\")\n",
        "\n",
        "\n",
        "\n",
        "# Call the function to write the .obj file\n",
        "write_obj_with_colors(pt_cloud_reshape, idx_critical_points, name, \"outputs/notebook\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AE6QmxhRbwsY",
        "mMIT1MeNSSO8",
        "Isb_97zOA8Tl",
        "_8W4gOI_P9a9"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "name": "PointNetClass.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
