{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok avec `PoinNet0_env`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applique le script get_cirtical_points.py à tous les fichiers .off d'un répertoire (`folder_path+dataset+\"/\"`) et enregistre les outputs dans le dossier `output_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "Dataset_path = '/home/pelissier/These-ATER/Papier_international3/Dataset/'\n",
    "Critical_pts_folder_path = '/home/pelissier/These-ATER/Papier_international3/PointNet/my_PointNet/Critical_pts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_off_files_recursive(folder_path, extension='*.off'):\n",
    "    # Get all .off files from the folder and its subfolders\n",
    "    off_files = glob.glob(os.path.join(folder_path, \"**\", extension), recursive=True)\n",
    "    \n",
    "    # Filter out files that contain 'SIMPL' in their name\n",
    "    off_files = [file for file in off_files if 'SMPL' not in os.path.basename(file)]\n",
    "    \n",
    "    return off_files\n",
    "\n",
    "def count_files_in_folder_recursive(folder_path):\n",
    "    file_count = 0\n",
    "    for _, _, files in os.walk(folder_path):\n",
    "        file_count += len(files)\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelNet40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a : 12311 fichiers .off dans le dataset ModelNet40\n",
      "Le dossier ModelNet40 existe déjà !\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "dataset = \"ModelNet40\"\n",
    "# Tous les path des fichiers .off de ModelNet40\n",
    "off_files = get_off_files_recursive(Dataset_path+dataset+\"/\"); print(f\"Il y a : {len(off_files)} fichiers .off dans le dataset {dataset}\")\n",
    "\n",
    "# Creation du dossier de sortie : Critical_pts/ModelNet40\n",
    "# Check if folder exists, and if not, create it\n",
    "modelnet40_path = Critical_pts_folder_path+dataset+\"/\"\n",
    "if not Path(modelnet40_path).exists(): Path(modelnet40_path).mkdir(parents=True, exist_ok=True)\n",
    "else : print(\"Le dossier \"+dataset+\" existe déjà !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# Les catégories de ModelNet40 \n",
    "categories = os.listdir(Dataset_path+dataset+\"/\"); print(len(categories))\n",
    "\n",
    "# Create one folder for each category in the output folder : Critical_pts/ModelNet40/category\n",
    "for category in categories:\n",
    "    category_folder = os.path.join(modelnet40_path, category)\n",
    "    if not Path(category_folder).exists():Path(category_folder).mkdir(parents=True, exist_ok=True)\n",
    "    #else: print(f\"Le dossier {category} existe déjà !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Path to the toto.py script\n",
    "kind_of_outputs = '{\"critical and non-critical points\": true, \"only critical points\": true, \"objet\": true}'\n",
    "affichage = \"True\"  # or \"False\", as required\n",
    "\n",
    "# Path to save failed file names\n",
    "failed_files_log = Critical_pts_folder_path+'failed_files.txt'\n",
    "\n",
    "\n",
    "def run_script(off_file):\n",
    "    category = \"_\".join(os.path.basename(off_file).split('_')[:-1])\n",
    "    category_folder = os.path.join(Critical_pts_folder_path, dataset, category)+'/'\n",
    "    \n",
    "    cmd = [\n",
    "        \"python\", \n",
    "        \"/home/pelissier/These-ATER/Papier_international3/PointNet/my_PointNet/get_critical_points.py\", \n",
    "        off_file, \n",
    "        category_folder, \n",
    "        \"--kind_of_outputs\", kind_of_outputs, \n",
    "        \"--affichage\", affichage\n",
    "    ]\n",
    "    #try:\n",
    "    # Capture output and error, prevent displaying errors\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    # Check if the process succeeded (returncode 0 means success)\n",
    "    if result.returncode != 0:\n",
    "        # If there is an error, return the file name to log it\n",
    "        return off_file\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     # Log the file if any exception occurs\n",
    "    #     return off_file\n",
    "    \n",
    "    return None  # No errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objectif : 61555, Créé : 13, Pbl : 0\n",
      "Objectif : 61555, Créé : 1265, Pbl : 0\n",
      "Objectif : 61555, Créé : 2507, Pbl : 0\n",
      "Objectif : 61555, Créé : 3760, Pbl : 0\n",
      "Objectif : 61555, Créé : 5013, Pbl : 0\n",
      "Objectif : 61555, Créé : 6269, Pbl : 0\n",
      "Objectif : 61555, Créé : 7510, Pbl : 0\n",
      "Objectif : 61555, Créé : 8763, Pbl : 0\n",
      "Objectif : 61555, Créé : 10011, Pbl : 0\n",
      "Objectif : 60830, Créé : 10525, Pbl : 145\n",
      "Objectif : 60125, Créé : 11075, Pbl : 286\n",
      "Objectif : 60125, Créé : 12330, Pbl : 286\n",
      "Objectif : 58960, Créé : 12405, Pbl : 519\n",
      "Objectif : 57710, Créé : 12405, Pbl : 769\n",
      "Objectif : 56460, Créé : 12405, Pbl : 1019\n",
      "Objectif : 56225, Créé : 13435, Pbl : 1066\n",
      "Objectif : 55110, Créé : 13555, Pbl : 1289\n",
      "Objectif : 53860, Créé : 13555, Pbl : 1539\n",
      "Objectif : 53400, Créé : 14360, Pbl : 1631\n",
      "Objectif : 53400, Créé : 15618, Pbl : 1631\n",
      "Objectif : 53400, Créé : 16855, Pbl : 1631\n",
      "Objectif : 52350, Créé : 17045, Pbl : 1841\n",
      "Objectif : 51100, Créé : 17045, Pbl : 2091\n",
      "Objectif : 49850, Créé : 17045, Pbl : 2341\n",
      "Objectif : 49510, Créé : 17979, Pbl : 2409\n",
      "Objectif : 49510, Créé : 19213, Pbl : 2409\n",
      "Objectif : 49510, Créé : 20460, Pbl : 2409\n",
      "Objectif : 49510, Créé : 21715, Pbl : 2409\n",
      "Objectif : 49510, Créé : 22970, Pbl : 2409\n",
      "Objectif : 49510, Créé : 24225, Pbl : 2409\n",
      "Objectif : 49510, Créé : 25460, Pbl : 2409\n",
      "Objectif : 49510, Créé : 26720, Pbl : 2409\n",
      "Objectif : 49510, Créé : 27975, Pbl : 2409\n",
      "Objectif : 49510, Créé : 29217, Pbl : 2409\n",
      "Objectif : 49510, Créé : 30465, Pbl : 2409\n",
      "Objectif : 49495, Créé : 31710, Pbl : 2412\n",
      "Objectif : 49490, Créé : 32958, Pbl : 2413\n",
      "Objectif : 49490, Créé : 34205, Pbl : 2413\n",
      "Objectif : 49490, Créé : 35440, Pbl : 2413\n",
      "Objectif : 48710, Créé : 35935, Pbl : 2569\n",
      "Objectif : 48705, Créé : 37165, Pbl : 2570\n",
      "Objectif : 48685, Créé : 38385, Pbl : 2574\n",
      "Objectif : 48675, Créé : 39638, Pbl : 2576\n",
      "Objectif : 48675, Créé : 40880, Pbl : 2576\n",
      "Objectif : 47735, Créé : 41180, Pbl : 2764\n",
      "Objectif : 47245, Créé : 41945, Pbl : 2862\n",
      "Objectif : 47245, Créé : 43211, Pbl : 2862\n",
      "Objectif : 47245, Créé : 44450, Pbl : 2862\n",
      "Objectif : 47245, Créé : 45718, Pbl : 2862\n",
      "Objectif : 47245, Créé : 46950, Pbl : 2862\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "failed_files = []\n",
    "\n",
    "# Using ThreadPoolExecutor for parallel execution\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:  # Adjust max_workers as needed\n",
    "    # Submit tasks to the executor\n",
    "    futures = {executor.submit(run_script, off_file): off_file for off_file in off_files}\n",
    "    \n",
    "    for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "        if i%250==0:\n",
    "            print(f\"Objectif : {(len(off_files)-len(failed_files))*5}, Créé : {count_files_in_folder_recursive(modelnet40_path)}, Pbl : {len(failed_files)}\")\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                failed_files.append(result)\n",
    "        except Exception as exc:\n",
    "            pass#print(exc)\n",
    "\n",
    "# Save the failed file names to a log file\n",
    "if failed_files:\n",
    "    with open(failed_files_log, 'w') as f:\n",
    "        for file in failed_files:\n",
    "            f.write(f\"{file}\\n\")\n",
    "else : \n",
    "    with open(failed_files_log, 'w') as f : f.write(\"Tout est ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autre dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import subprocess\n",
    "\n",
    "# Define the output path and other arguments\n",
    "output_path = \"/home/pelissier/These-ATER/Papier_international3/PointNet/my_PointNet/Critical_pts/ModelNet40/\"\n",
    "kind_of_outputs = '{\"critical and non-critical points\": true, \"only critical points\": true, \"objet\": true}'\n",
    "affichage = \"True\"  # or \"False\", as required\n",
    "\n",
    "# Function to run the script\n",
    "def run_script(input_path):\n",
    "    command = [\n",
    "        \"python\", \n",
    "        \"/home/pelissier/These-ATER/Papier_international3/PointNet/my_PointNet/get_critical_points.py\", \n",
    "        input_path, \n",
    "        output_path, \n",
    "        \"--kind_of_outputs\", kind_of_outputs, \n",
    "        \"--affichage\", affichage\n",
    "    ]\n",
    "\n",
    "    # Use subprocess to execute the command\n",
    "    subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "        \n",
    "\n",
    "# # Use ProcessPoolExecutor with tqdm for progress tracking\n",
    "# with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#     # Create a tqdm progress bar\n",
    "#     with tqdm(total=len(off_files), desc=\"Processing .off files\") as pbar:\n",
    "#         # Submit tasks to the executor\n",
    "#         futures = {executor.submit(run_script, file): file for file in off_files}\n",
    "        \n",
    "#         # Update the progress bar as each task is completed\n",
    "#         for future in concurrent.futures.as_completed(futures):\n",
    "#             pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
